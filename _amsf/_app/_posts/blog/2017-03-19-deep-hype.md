---
layout: post
title: Why is deep learning so hyped?
excerpt: Explaining the importance of deep learning
tag: blog-post
scheme-text: "#fff"
scheme-link: "#9ed8d8"
scheme-hover: "#fff"
scheme-code: "#39beb6"
scheme-bg: "#317979"
plugin: lightense
---


## The Problem

Unfortunately this project doesn't work with GitHub Pages or GitHub Pages for projects. There're some factors that prevent it from generating pages:

- Many features Almace Scaffolding provides like live reloading, Less support, inline SVG, and HTML minification are implemented using [Grunt.js](http://gruntjs.com/), it's not supported by GitHub Pages.
- Almace Scaffolding uses the latest pre-release Jekyll, so not all features are supported by GitHub Pages renderers.
- GItHub Pages build server [overwrites the `source` settings](https://help.github.com/articles/pages-don-t-build-unable-to-run-jekyll#source-setting). This prevent it generating pages from current file structure.

<img src="assets/img/content.jpg">

What exactly is deep learning and why should we be hyped?

Like most of you reading this article, I am a newbie to deep learning too. With a basic computer science degree, I entered this arena after I saw so much excitement among the people in this community. And once I knew what it was, I got hooked too.

After Google open-sourced their machine learning library Tensorflow, there has been a lot of talk about ‘deep learning’ and for those who are not from a technical background, you may wonder what exactly all the hype is about. So without further ado, let’s get into it.

Deep learning is a computer algorithm inspired by the structure of our brains, and neurologists think there’s something similar but a lot more complicated in our brains that help us humans do so complicated things.
A brief history

The algorithms for neural networks were invented in the 60’s, but it’s only now that we have enough computation power to carry it out on a large-scale. And our brain has around 1 billion neurons, so we still need a lot of computating power to reach that stage.

Some important people who have worked in this field are Geoffrey Hinton, Yoshua Bengio, Andrej Karpathy, Yann Le Cunn, Andrew Ng, Sebastian Thrun, Ian Goodfellow. Be sure to check them out if interested.
So how does it work?

Traditional programming algorithms make us specify every case that can fall upon it. It breaks if an unspecified case occurs. The deep learning algorithm, however, looks at a lot of inputs and their corresponding outputs and tries to learn a pattern between them. Thus, after this training it will be able to predict an output when an unknown input is given. A fun visualization is here.

Underneath, there’s a lot of matrix multiplications, calculus and statistics. Deep learning is actually an intersection of computer science, data science, neuroscience, and math. We write code that learns by itself and doesn’t need all cases specifically written.
So does it have neurons like our brains have?

Yes they do!
